{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random-forest.ipynb",
      "provenance": [],
      "mount_file_id": "1YoxQI-KWD43CireAkB_Aj4YvogigsjWN",
      "authorship_tag": "ABX9TyMbvpGzMK2MMIwfO1B3YdFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhivyapm/divya/blob/master/Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y47GXRzCBSVH",
        "colab_type": "text"
      },
      "source": [
        "I found the information about how the model works in this website\n",
        "https://medium.com/coinmonks/what-is-entropy-and-why-information-gain-is-matter-4e85d46d2f01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2n8BFeoBPzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # to read the dataset and convert the dataset to DataFrame which is in table format\n",
        "import numpy as np # numpy is for computing, here I'm using this package for randomly select the rows from the dataset\n",
        "import random # to randomly select the datapoints from dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/satelite.csv')\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXTT8qoSAsn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_copy  = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEloKOZAAtZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df_copy.drop('Column37',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAuQ7hcqAwSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce623697-70b9-4178-9069-386e9e0aa1e7"
      },
      "source": [
        "features = list(df1.columns)\n",
        "random.seed(30) # If you want to generate the same number every time,before doing the shuffle\n",
        "df = df.sample(frac=1)# shuffle the dataset\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6435, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq1Ic6BtAysH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f28b0e5c-3631-48bb-d356-014a1baa1826"
      },
      "source": [
        "#train_test_Split\n",
        "train_size = int(0.9 * len(df)) #train_size =5791\n",
        "X_train = df[features][:train_size] # X_train takes the values of the columns from 1 to 36 from the dataset upto the train_size rows(5791 rows)\n",
        "y_train = df['Column37'][:train_size] #y_train takes the last column values which is label upto the train_size(5791 rows)\n",
        "X_test = df[features][train_size:] # X_test takes the values of the columns from 1 to 36 starting from rows 5791 upto the dataset length which is 6435\n",
        "y_test = df['Column37'][train_size:] # y_test takes the last column values which is label starting from rows 5791 upto the dataset length which is 6435\n",
        "print(X_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Column1  Column2  Column3  ...  Column34  Column35  Column36\n",
            "6368       76       89      106  ...        91       100        83\n",
            "4022       71       77       86  ...        81        82        65\n",
            "1834       71       79       91  ...        91        96        78\n",
            "1111       60       91      100  ...       104       112        92\n",
            "1735       52       77       93  ...        73        90        76\n",
            "...       ...      ...      ...  ...       ...       ...       ...\n",
            "696        68       71       79  ...        71        76        59\n",
            "4993       80       89       94  ...        87        89        67\n",
            "1088       60      111      120  ...       111       123       100\n",
            "425        90      109      112  ...       115       114        90\n",
            "4856       56       56       69  ...        75       101        87\n",
            "\n",
            "[5791 rows x 36 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnuCTgOoA47O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating the bootstrap that is taking sample from train set and left out samples in dataset will be taken as out-of-bag which is used to test the model performance\n",
        "def n_bootstrap(X_train, y_train):\n",
        "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True)) #it as the index of the sample selected from the training set\n",
        "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices] # it as the index of the left over samples in the training set\n",
        "    X_bootstrap = X_train.iloc[bootstrap_indices].values # here it takes the values of the specific index from the training\n",
        "    y_bootstrap = y_train[bootstrap_indices] # it takes the array elements of the specific indices(labels)\n",
        "    X_oob = X_train.iloc[oob_indices].values # it takes the values of the left over samples in the training set\n",
        "    y_oob = y_train[oob_indices] # it takes the array elements from the left over samples in the training set(labels)\n",
        "    return X_bootstrap, y_bootstrap, X_oob, y_oob # returns all the values of bootstrap and oob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BJA7NbiA8-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the Entropy(measure of disorder)\n",
        "#To which group does this sample belongs to\n",
        "#Entropy controls how a Decision Tree decides to split the data.\n",
        "#where entropy takes in a probability of a class within a node \n",
        "def entropy(p):\n",
        "    if p == 0:\n",
        "        return 0\n",
        "    elif p == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIwXObMKBB4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate the information gain to compare the entropy before and after split\n",
        "#Information_gain takes in a list of the classes from the left and right child and returns the information gain of that particular split.\n",
        "def information_gain(left_child, right_child):\n",
        "    parent = left_child + right_child\n",
        "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
        "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
        "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
        "    IG_p = entropy(p_parent) #calculate the entropy of parent node\n",
        "    IG_l = entropy(p_left) #calculate the entropy of left child node\n",
        "    IG_r = entropy(p_right) #calculate the entropy of right child node\n",
        "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r #return the information gain of parent and childs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}